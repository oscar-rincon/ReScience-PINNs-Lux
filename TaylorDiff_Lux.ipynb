{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 9.2041686e-5\n",
      "Epoch: 200, Loss: 2.3943021e-5\n",
      "Epoch: 300, Loss: 1.3304576e-5\n",
      "Epoch: 400, Loss: 1.006307e-5\n",
      "Epoch: 500, Loss: 8.013504e-6\n",
      "Epoch: 600, Loss: 6.537302e-6\n",
      "Epoch: 700, Loss: 5.4696675e-6\n",
      "Epoch: 800, Loss: 4.67683e-6\n",
      "Epoch: 900, Loss: 4.060914e-6\n",
      "Epoch: 1000, Loss: 3.5580517e-6\n",
      "Epoch: 1100, Loss: 3.130429e-6\n",
      "Epoch: 1200, Loss: 8.34266e-6\n",
      "Epoch: 1300, Loss: 3.2771097e-6\n",
      "Epoch: 1400, Loss: 2.8803854e-6\n",
      "Epoch: 1500, Loss: 2.5371392e-6\n",
      "Epoch: 1600, Loss: 2.233566e-6\n",
      "Epoch: 1700, Loss: 8.884234e-6\n",
      "Epoch: 1800, Loss: 2.218052e-6\n",
      "Epoch: 1900, Loss: 1.9036665e-6\n",
      "Epoch: 2000, Loss: 1.6403837e-6\n",
      "Epoch: 2100, Loss: 1.4173472e-6\n",
      "Epoch: 2200, Loss: 1.2291441e-6\n",
      "Epoch: 2300, Loss: 1.5624073e-6\n",
      "Epoch: 2400, Loss: 9.771035e-7\n",
      "Epoch: 2500, Loss: 8.555381e-7\n",
      "Epoch: 2600, Loss: 7.5751376e-7\n",
      "Epoch: 2700, Loss: 6.766129e-7\n",
      "Epoch: 2800, Loss: 0.0004099977\n",
      "Epoch: 2900, Loss: 6.218015e-7\n",
      "Epoch: 3000, Loss: 5.331904e-7\n",
      "Epoch: 3100, Loss: 4.841846e-7\n",
      "Epoch: 3200, Loss: 4.453135e-7\n",
      "Epoch: 3300, Loss: 1.37366915e-5\n",
      "Epoch: 3400, Loss: 7.3816875e-7\n",
      "Epoch: 3500, Loss: 4.4965225e-7\n",
      "Epoch: 3600, Loss: 1.4802995e-6\n",
      "Epoch: 3700, Loss: 3.4381225e-7\n",
      "Epoch: 3800, Loss: 8.4622087e-7\n",
      "Epoch: 3900, Loss: 0.0004072885\n",
      "Epoch: 4000, Loss: 3.1171842e-7\n",
      "Epoch: 4100, Loss: 3.1233336e-5\n",
      "Epoch: 4200, Loss: 3.136745e-7\n",
      "Epoch: 4300, Loss: 2.752701e-7\n",
      "Epoch: 4400, Loss: 1.1142404e-6\n",
      "Epoch: 4500, Loss: 7.59178e-7\n",
      "Epoch: 4600, Loss: 3.3297798e-7\n",
      "Epoch: 4700, Loss: 2.2748787e-7\n",
      "Epoch: 4800, Loss: 0.00023341912\n",
      "Epoch: 4900, Loss: 2.669874e-7\n",
      "Epoch: 5000, Loss: 4.542496e-6\n"
     ]
    }
   ],
   "source": [
    "using Lux, Random,TaylorDiff, ComponentArrays, Optimisers,Zygote, Plots,ForwardDiff, Statistics\n",
    "\n",
    "rng = MersenneTwister()\n",
    "Random.seed!(rng, 1)\n",
    "\n",
    "# Define the model\n",
    "model = Chain(Dense(1 => 50, tanh), Dense(50 => 50, tanh), Dense(50 => 1)) \n",
    "\n",
    "# Initialize model parameters\n",
    "ps, st = Lux.setup(Xoshiro(0), model)\n",
    "ps = ps |> ComponentArray\n",
    "\n",
    "# Function to evaluate the model\n",
    "function trial(model, x, ps, st)\n",
    "    u, st = Lux.apply(model, x, ps, st)\n",
    "    return u\n",
    "end\n",
    "\n",
    "f(x) = trial(model, x, ps, st)\n",
    "\n",
    "# Define the loss function\n",
    "x = collect(range(-1f0, 1f0, length=200))\n",
    "x = reshape(x, 1, :)\n",
    "y = Float32.(cos.(x))\n",
    "data = (x, y)\n",
    "\n",
    "opt = Adam(0.01f0)\n",
    "\n",
    "function trial(model, x, ps, st)\n",
    "    u, st = Lux.apply(model, x, ps, st)\n",
    "    return u\n",
    "end\n",
    "\n",
    "# Define the loss function\n",
    "function loss_function(model, ps, st, data)\n",
    "    x = data[1]\n",
    "    y = data[2]\n",
    "    f(x) = trial(model, x, ps, st)\n",
    "    y_pred = f(x)\n",
    "    dydx = TaylorDiff.derivative(f, x, Float32.(ones(size(x))), Val(1)) \n",
    "    error = y_pred .- y\n",
    "    loss = mean(error.^2)\n",
    "    return loss, st, ()\n",
    "end\n",
    "\n",
    "ps, st = Lux.setup(rng, model)\n",
    "loss_function(model, ps, st, data)\n",
    "\n",
    "tstate = Training.TrainState(model, ps, st, opt)\n",
    "\n",
    "grads, loss, stats, ts = Lux.Training.compute_gradients(AutoZygote(), loss_function, data, tstate)\n",
    "Lux.Training.apply_gradients(ts, grads)\n",
    "\n",
    "# Training loop\n",
    "epochs = 5000\n",
    "for epoch in 1:epochs\n",
    "    grads, loss, stats, ts = Lux.Training.compute_gradients(AutoZygote(), loss_function, data, tstate)\n",
    "    tstate = Lux.Training.apply_gradients(ts, grads)\n",
    "    if epoch % 100 == 0\n",
    "        println(\"Epoch: $epoch, Loss: $loss\")\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
